#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Conversor de √≠ndice FAISS para PyTorch GPU

Este script converte o √≠ndice FAISS existente para o formato PyTorch,
extrai os embeddings e os salva como arquivo .npy para uso com GPU.

Autor: @AgenteM_DevFastAPI
Vers√£o: 1.0
Data: Janeiro 2025
"""

import json
import logging
import time
from pathlib import Path
from typing import Optional

import numpy as np
import faiss

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core_logic.constants import (
    FAISS_INDEX_DIR,
    FAISS_INDEX_FILE,
    FAISS_DOCUMENTS_FILE,
    FAISS_METADATA_FILE,
    LOGS_DIR
)

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Criar handler para arquivo de log
LOGS_DIR.mkdir(parents=True, exist_ok=True)
file_handler = logging.FileHandler(LOGS_DIR / "faiss_to_pytorch_converter.log")
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)

def extract_embeddings_from_faiss(index_path: Path) -> Optional[np.ndarray]:
    """
    Extrai embeddings do √≠ndice FAISS.
    
    Args:
        index_path: Caminho para o arquivo do √≠ndice FAISS
        
    Returns:
        np.ndarray: Array com os embeddings extra√≠dos
    """
    try:
        logger.info(f"Carregando √≠ndice FAISS de: {index_path}")
        
        # Usar diret√≥rio tempor√°rio para evitar problemas com Unicode
        import tempfile
        import shutil
        from uuid import uuid4
        
        temp_dir = "C:\\Temp" if os.name == "nt" else "/tmp"
        if not Path(temp_dir).exists():
            Path(temp_dir).mkdir(parents=True, exist_ok=True)
        
        with tempfile.TemporaryDirectory(dir=temp_dir) as temp_path:
            temp_file_path = Path(temp_path) / f"faiss_index_{uuid4().hex}.bin"
            shutil.copy2(str(index_path), str(temp_file_path))
            index = faiss.read_index(str(temp_file_path))
        
        logger.info(f"√çndice carregado: {index.ntotal} vetores, dimens√£o {index.d}")
        
        # Verificar tipo do √≠ndice
        if hasattr(index, 'reconstruct_n'):
            # √çndice que suporta reconstru√ß√£o
            logger.info("Extraindo embeddings usando reconstruct_n...")
            embeddings = index.reconstruct_n(0, index.ntotal)
            
        elif hasattr(index, 'xb') and index.xb is not None:
            # √çndice Flat - acesso direto aos dados
            logger.info("Extraindo embeddings de √≠ndice Flat...")
            embeddings = faiss.vector_to_array(index.xb).reshape(index.ntotal, index.d)
            
        else:
            # Tentar extrair usando reconstruct individual
            logger.info("Extraindo embeddings usando reconstruct individual...")
            embeddings = np.zeros((index.ntotal, index.d), dtype=np.float32)
            
            batch_size = 1000
            for i in range(0, index.ntotal, batch_size):
                end_idx = min(i + batch_size, index.ntotal)
                for j in range(i, end_idx):
                    try:
                        embeddings[j] = index.reconstruct(j)
                    except Exception as e:
                        logger.warning(f"Erro ao reconstruir vetor {j}: {e}")
                        # Preencher com zeros se n√£o conseguir reconstruir
                        embeddings[j] = np.zeros(index.d, dtype=np.float32)
                
                if i % 5000 == 0:
                    logger.info(f"Progresso: {i}/{index.ntotal} embeddings extra√≠dos")
        
        logger.info(f"Embeddings extra√≠dos: shape {embeddings.shape}")
        return embeddings
        
    except Exception as e:
        logger.error(f"Erro ao extrair embeddings: {str(e)}")
        return None

def convert_faiss_to_pytorch() -> bool:
    """
    Converte o √≠ndice FAISS para formato PyTorch.
    
    Returns:
        bool: True se convers√£o foi bem-sucedida
    """
    try:
        logger.info("Iniciando convers√£o FAISS para PyTorch...")
        start_time = time.time()
        
        # Verificar se os arquivos FAISS existem
        index_path = FAISS_INDEX_DIR / FAISS_INDEX_FILE
        documents_path = FAISS_INDEX_DIR / FAISS_DOCUMENTS_FILE
        metadata_path = FAISS_INDEX_DIR / FAISS_METADATA_FILE
        
        if not all([index_path.exists(), documents_path.exists(), metadata_path.exists()]):
            logger.error("Arquivos FAISS n√£o encontrados. Execute a indexa√ß√£o primeiro.")
            return False
        
        # 1. Extrair embeddings do FAISS
        logger.info("Extraindo embeddings do √≠ndice FAISS...")
        embeddings = extract_embeddings_from_faiss(index_path)
        
        if embeddings is None:
            logger.error("Falha ao extrair embeddings")
            return False
        
        # 2. Salvar embeddings como arquivo .npy
        embeddings_path = FAISS_INDEX_DIR / "embeddings.npy"
        logger.info(f"Salvando embeddings em: {embeddings_path}")
        np.save(str(embeddings_path), embeddings)
        
        # 3. Verificar consist√™ncia com documentos
        with open(documents_path, 'r', encoding='utf-8') as f:
            documents = json.load(f)
        
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata_data = json.load(f)
            metadata = metadata_data.get("documents_metadata", [])
        
        logger.info(f"Verificando consist√™ncia:")
        logger.info(f"  - Embeddings: {embeddings.shape[0]}")
        logger.info(f"  - Documentos: {len(documents)}")
        logger.info(f"  - Metadados: {len(metadata)}")
        
        if embeddings.shape[0] != len(documents):
            logger.warning(f"Inconsist√™ncia detectada: {embeddings.shape[0]} embeddings vs {len(documents)} documentos")
        
        # 4. Criar arquivo de informa√ß√µes da convers√£o
        conversion_info = {
            "conversion_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "original_faiss_index": str(index_path),
            "embeddings_shape": list(embeddings.shape),
            "embeddings_dtype": str(embeddings.dtype),
            "documents_count": len(documents),
            "metadata_count": len(metadata),
            "conversion_time_seconds": time.time() - start_time
        }
        
        conversion_info_path = FAISS_INDEX_DIR / "pytorch_conversion_info.json"
        with open(conversion_info_path, 'w', encoding='utf-8') as f:
            json.dump(conversion_info, f, indent=2, ensure_ascii=False)
        
        elapsed_time = time.time() - start_time
        logger.info(f"‚úÖ Convers√£o conclu√≠da em {elapsed_time:.2f}s")
        logger.info(f"Arquivos criados:")
        logger.info(f"  - {embeddings_path}")
        logger.info(f"  - {conversion_info_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"Erro na convers√£o: {str(e)}")
        return False

def verify_pytorch_data() -> bool:
    """
    Verifica se os dados PyTorch foram criados corretamente.
    
    Returns:
        bool: True se dados est√£o v√°lidos
    """
    try:
        logger.info("Verificando dados PyTorch...")
        
        embeddings_path = FAISS_INDEX_DIR / "embeddings.npy"
        documents_path = FAISS_INDEX_DIR / FAISS_DOCUMENTS_FILE
        metadata_path = FAISS_INDEX_DIR / FAISS_METADATA_FILE
        conversion_info_path = FAISS_INDEX_DIR / "pytorch_conversion_info.json"
        
        # Verificar se arquivos existem
        missing_files = []
        for path in [embeddings_path, documents_path, metadata_path, conversion_info_path]:
            if not path.exists():
                missing_files.append(str(path))
        
        if missing_files:
            logger.error(f"Arquivos n√£o encontrados: {missing_files}")
            return False
        
        # Carregar e verificar embeddings
        embeddings = np.load(str(embeddings_path))
        logger.info(f"Embeddings carregados: shape {embeddings.shape}, dtype {embeddings.dtype}")
        
        # Carregar documentos
        with open(documents_path, 'r', encoding='utf-8') as f:
            documents = json.load(f)
        
        # Carregar metadados
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata_data = json.load(f)
            metadata = metadata_data.get("documents_metadata", [])
        
        # Carregar info da convers√£o
        with open(conversion_info_path, 'r', encoding='utf-8') as f:
            conversion_info = json.load(f)
        
        # Verificar consist√™ncia
        checks = {
            "embeddings_shape_consistency": embeddings.shape[0] == len(documents),
            "metadata_consistency": len(documents) == len(metadata),
            "embeddings_not_empty": embeddings.shape[0] > 0,
            "embeddings_valid_dtype": embeddings.dtype in [np.float32, np.float64],
            "conversion_info_valid": "conversion_date" in conversion_info
        }
        
        logger.info("Resultados da verifica√ß√£o:")
        all_passed = True
        for check_name, passed in checks.items():
            status = "‚úÖ PASSOU" if passed else "‚ùå FALHOU"
            logger.info(f"  {check_name}: {status}")
            if not passed:
                all_passed = False
        
        if all_passed:
            logger.info("‚úÖ Todos os dados PyTorch est√£o v√°lidos")
        else:
            logger.error("‚ùå Problemas detectados nos dados PyTorch")
        
        return all_passed
        
    except Exception as e:
        logger.error(f"Erro na verifica√ß√£o: {str(e)}")
        return False

def main():
    """
    Fun√ß√£o principal.
    """
    print("Conversor FAISS para PyTorch GPU")
    print("=" * 40)
    
    # Verificar se j√° existe convers√£o
    embeddings_path = FAISS_INDEX_DIR / "embeddings.npy"
    if embeddings_path.exists():
        print("‚ö†Ô∏è  Embeddings PyTorch j√° existem.")
        response = input("Deseja reconverter? (s/N): ").strip().lower()
        if response not in ['s', 'sim', 'y', 'yes']:
            print("Verificando dados existentes...")
            if verify_pytorch_data():
                print("‚úÖ Dados PyTorch v√°lidos. Convers√£o n√£o necess√°ria.")
                return
            else:
                print("‚ùå Dados PyTorch inv√°lidos. Reconvertendo...")
    
    # Executar convers√£o
    if convert_faiss_to_pytorch():
        print("\n‚úÖ Convers√£o conclu√≠da com sucesso!")
        
        # Verificar resultado
        if verify_pytorch_data():
            print("‚úÖ Dados PyTorch verificados e v√°lidos")
            print("\nüöÄ Agora voc√™ pode usar o PyTorchGPURetriever!")
        else:
            print("‚ùå Problemas detectados ap√≥s convers√£o")
    else:
        print("‚ùå Falha na convers√£o")

if __name__ == "__main__":
    main()