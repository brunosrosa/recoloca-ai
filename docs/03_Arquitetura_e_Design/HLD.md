---
sticker: lucide//heart-crack
---
# High-Level Design (HLD) do Projeto Recoloca.ai

**Vers√£o**: 0.9 (Pr√©-Revis√£o Interativa)

**Data de Cria√ß√£o**: 03 de junho de 2025

**Data de √öltima Atualiza√ß√£o**: 03 de junho de 2025

**Autor**: @AgenteM_ArquitetoHLD (com supervis√£o do Maestro Bruno S. Rosa)

**Baseado em**:
- [[docs/01_Guias_Centrais/PLANO_MESTRE_RECOLOCA_AI.md]] (v1.5)
    
- [[docs/02_Requisitos/ERS.md]] (v0.5)
    
- [[docs/01_Guias_Centrais/GUIA_AVANCADO.md]] (v2.3)
    
- [[docs/03_Arquitetura_e_Design/ADR/ADR_001_Ferramentas_Core.md]] (v1.0)
    
## 1. Introdu√ß√£o

### 1.1. Prop√≥sito

Este documento descreve a arquitetura de alto n√≠vel (High-Level Design - HLD) do sistema **Recoloca.ai**. O objetivo √© fornecer uma vis√£o geral dos principais componentes do sistema, suas responsabilidades, intera√ß√µes e as tecnologias chave empregadas. Este HLD servir√° como guia para o desenvolvimento do MVP e futuras itera√ß√µes, garantindo que as decis√µes de design estejam alinhadas com os requisitos funcionais (RFs) e n√£o funcionais (RNFs) definidos na [[docs/02_Requisitos/ERS.md]] e com as escolhas tecnol√≥gicas registradas no [[docs/03_Arquitetura_e_Design/ADR/ADR_001_Ferramentas_Core.md]].
### 1.2. Escopo

O escopo deste HLD abrange os principais subsistemas do Recoloca.ai, incluindo:

- A aplica√ß√£o Frontend (PWA).
    
- A API Backend.
    
- Os servi√ßos de Backend as a Service (BaaS) para autentica√ß√£o e persist√™ncia de dados.
    
- A integra√ß√£o com Modelos de Linguagem Ampla (LLMs).
    
- O sistema de Retrieval Augmented Generation (RAG) para contextualiza√ß√£o da IA.
    
- As ferramentas de automa√ß√£o e CI/CD.
    
- A futura Extens√£o de Navegador (P√≥s-MVP).
    

Detalhes de design de baixo n√≠vel (LLD) para m√≥dulos espec√≠ficos ser√£o documentados separadamente em [[docs/03_Arquitetura_e_Design/LLD/]].
### 1.3. Siglas e Termos

Consulte o [[docs/01_Guias_Centrais/GLOSSARIO_Recoloca_AI.md]] (v1.1) para defini√ß√µes de termos e siglas utilizados neste documento.
## 2. Vis√£o Geral da Arquitetura

O Recoloca.ai √© projetado como um sistema distribu√≠do, composto por uma aplica√ß√£o frontend (PWA), uma API backend, servi√ßos de BaaS, e integra√ß√µes com servi√ßos de IA e automa√ß√£o. A arquitetura visa ser modular, escal√°vel e manuten√≠vel, suportando a metodologia de "Desenvolvimento Solo √Ågil Aumentado por IA".

**Principais Componentes:**

1. **Frontend (PWA - Flutter):** Interface com o usu√°rio, l√≥gica de apresenta√ß√£o, gerenciamento de estado local e comunica√ß√£o com a API Backend.
    
2. **API Backend (Python/FastAPI):** L√≥gica de neg√≥cios principal, orquestra√ß√£o de chamadas para LLMs, intera√ß√£o com o Supabase e o sistema RAG.
    
3. **Supabase (BaaS):** Gerencia autentica√ß√£o de usu√°rios, banco de dados PostgreSQL (dados da aplica√ß√£o, metadados de CVs) e armazenamento de arquivos (ex: PDFs de curr√≠culos).
    
4. **Google Gemini LLMs (via OpenRouter):** Fornece as capacidades de processamento de linguagem natural para otimiza√ß√£o de CV, coaching, importa√ß√£o de vagas, etc.
    
5. **Sistema RAG Local (LangChain + FAISS-GPU + `BAAI/bge-m3`):** Indexa a "Documenta√ß√£o Viva" e outros materiais de refer√™ncia para fornecer contexto din√¢mico aos LLMs e Agentes de IA.
    
6. **Agentes de IA (Trae IDE):** N√£o s√£o um componente de runtime da aplica√ß√£o do _usu√°rio final_, mas sim do ambiente de _desenvolvimento e metodologia_. Interagem com o sistema RAG e os LLMs para auxiliar o Maestro.
    
7. **Pipedream (Automa√ß√£o):** Orquestra fluxos de CI/CD e outras automa√ß√µes (ex: gatilhos para reindexar o RAG).
    
8. **Extens√£o** de **Navegador (Chrome - P√≥s-MVP):** Coleta dados de vagas de portais de emprego.
    
## 3. Diagrama da Arquitetura de Alto N√≠vel

O diagrama abaixo ilustra os principais componentes do sistema Recoloca.ai e suas intera√ß√µes.

```mermaid
graph RL
    subgraph "Usu√°rio Final"
        U["üë§ Usu√°rio (Profissional)"]
    end

    subgraph "Ambiente de Desenvolvimento e Metodologia"
        Maestro["üßë‚Äçüíª Maestro (Bruno S. Rosa)"]
        TraeIDE["üõ†Ô∏è Trae IDE"]
        AgentesIA["ü§ñ Agentes de IA Mentores<br>(Inclui @AgenteM_Documentacao)"]
        RAG_Dev["üìö Sistema RAG Local<br>(LangChain, FAISS-GPU, BAAI/bge-m3)"]
        Obsidian["üìì Obsidian (Documenta√ß√£o Viva)"]
        GitRepo_Dev["üì¶ Reposit√≥rio Git<br>(Fonte da Verdade)"]

        Maestro -- "Interage com" --> TraeIDE
        TraeIDE -- "Orquestra" --> AgentesIA
        AgentesIA -- "Utiliza para Contexto" --> RAG_Dev
        AgentesIA -- "Consultam" --> GeminiAPI_Dev["üåê Google Gemini APIs<br>(via OpenRouter)"]
        AgentesIA -- "Cria/Atualiza Documentos" --> Obsidian
        Maestro -- "Revisa e Cura Documentos" --> Obsidian
        Obsidian -- "Fonte para" --> RAG_Dev
        Obsidian -- "Sincroniza com" --> GitRepo_Dev
        Maestro -- "Commits/Pushes para" --> GitRepo_Dev
    end

    subgraph "Sistema Recoloca.ai (Produ√ß√£o)"
        Frontend_PWA["üì± Frontend PWA<br>(Flutter Web)<br>Hospedado: Vercel"]
        Backend_API["‚öôÔ∏è API Backend<br>(Python/FastAPI)<br>Hospedado: Render"]
        Supabase["‚òÅÔ∏è Supabase (BaaS)<br>- Autentica√ß√£o<br>- PostgreSQL DB<br>- Storage (PDFs CVs)"]
        GeminiAPI_Prod["üåê Google Gemini APIs<br>(via OpenRouter)<br>Para: Otimiza√ß√£o CV, Coach, Importa√ß√£o Vagas"]
        RAG_Prod_Context_Source["(L√≥gica de acesso ao RAG<br>para contexto em runtime)"]

        U -- "Interage via HTTPS" --> Frontend_PWA
        Frontend_PWA -- "Chamadas API (HTTPS/REST)" --> Backend_API
        Backend_API -- "Consultas SQL, Auth, Storage" --> Supabase
        Backend_API -- "Chamadas API" --> GeminiAPI_Prod
        Backend_API -- "Consulta (Interna)" --> RAG_Prod_Context_Source
        RAG_Prod_Context_Source -. "Contexto injetado no prompt" .-> GeminiAPI_Prod

        %% Extens√£o P√≥s-MVP
        Extensao["üåê Extens√£o Chrome (P√≥s-MVP)"]
        U -- "Usa" --> Extensao
        Extensao -- "Chamadas API (HTTPS/REST)" --> Backend_API
    end

    subgraph "Ferramentas de Opera√ß√£o e Automa√ß√£o"
        Pipedream["üöÄ Pipedream<br>(CI/CD, Automa√ß√µes)"]

        GitRepo_Dev -- "Gatilho para (CI/CD)" --> Pipedream
        Pipedream -- "Deploy" --> Frontend_PWA
        Pipedream -- "Deploy" --> Backend_API
        Pipedream -- "Pode acionar<br>Reindexa√ß√£o RAG" --> RAG_Dev
    end

    %% Estiliza√ß√£o para clareza
    classDef user fill:#D6EAF8,stroke:#2E86C1,stroke-width:2px;
    classDef devEnv fill:#E8DAEF,stroke:#8E44AD,stroke-width:2px;
    classDef prodSys fill:#D5F5E3,stroke:#28B463,stroke-width:2px;
    classDef opsTools fill:#FCF3CF,stroke:#F39C12,stroke-width:2px;

    class U user;
    class Maestro,TraeIDE,AgentesIA,RAG_Dev,Obsidian,GeminiAPI_Dev,GitRepo_Dev devEnv;
    class Frontend_PWA,Backend_API,Supabase,GeminiAPI_Prod,RAG_Prod_Context_Source,Extensao prodSys;
    class Pipedream opsTools;
```

**Nota sobre o Diagrama:**

- O "Sistema RAG Local" no ambiente de desenvolvimento √© a infraestrutura (`rag_infra/`) que indexa a "Documenta√ß√£o Viva".
    
- O n√≥ "L√≥gica de acesso ao RAG para contexto em runtime" no sistema de produ√ß√£o representa a funcionalidade pela qual o Backend API acessa e utiliza os _resultados_ do processo de RAG (os chunks de texto relevantes) para enriquecer os prompts enviados aos LLMs em runtime, quando necess√°rio para funcionalidades como o Coach IA. A implementa√ß√£o exata de como o √≠ndice RAG (criado no ambiente de dev) √© disponibilizado ou consultado pelo backend em produ√ß√£o (seja por uma c√≥pia do √≠ndice, uma API interna, ou outro mecanismo) ser√° detalhada no LLD.
    
## 4. Descri√ß√£o dos Componentes

### 4.1. Frontend (PWA - Flutter)

- **Tecnologia:** Flutter (Dart), compilado para Web (PWA).
    
- **Hospedagem:** Vercel (ou similar).
    
- **Responsabilidades:**
    
    - Renderizar a interface do usu√°rio (UI) e gerenciar a experi√™ncia do usu√°rio (UX).
        
    - Gerenciar o estado da aplica√ß√£o no lado do cliente (ex: Provider, Riverpod).
        
    - Realizar chamadas HTTPS/REST para a API Backend para obter e enviar dados.
        
    - Lidar com a entrada do usu√°rio e valida√ß√µes no lado do cliente.
        
    - Implementar a l√≥gica de apresenta√ß√£o das funcionalidades (Kanban, formul√°rios de CV, Chatbot UI, etc.).
        
    - Armazenamento local (ex: SharedPreferences) para prefer√™ncias do usu√°rio ou cache leve.
        
- **Intera√ß√µes Chave:**
    
    - Com o Usu√°rio: Recebe inputs, exibe informa√ß√µes.
        
    - Com a API Backend: Envia requisi√ß√µes para todas as opera√ß√µes de dados e l√≥gica de neg√≥cios.
        
### 4.2. API Backend (Python/FastAPI)

- **Tecnologia:** Python 3.10+, FastAPI.
    
- **Hospedagem:** Render (ou similar).
    
- **Responsabilidades:**
    
    - Expor endpoints RESTful seguros para o Frontend PWA e a Extens√£o de Navegador.
        
    - Implementar a l√≥gica de neg√≥cios principal da aplica√ß√£o (regras de valida√ß√£o, processamento de dados).
        
    - Orquestrar chamadas para os servi√ßos do Supabase (autentica√ß√£o, banco de dados, storage).
        
    - Orquestrar chamadas para as APIs do Google Gemini (via OpenRouter) para funcionalidades de IA.
        
    - Integrar-se com o sistema RAG para fornecer contexto aos LLMs quando necess√°rio em runtime (ex: para o Coach IA).
        
    - Gerenciar a l√≥gica de parsing de PDFs de curr√≠culos (usando `pymupdf`, `Tesseract`, e LLMs).
        
    - Implementar a l√≥gica de tiers (Freemium/Premium) e controle de acesso a funcionalidades.
        
- **Intera√ß√µes Chave:**
    
    - Com o Frontend PWA/Extens√£o: Recebe requisi√ß√µes, envia respostas JSON.
        
    - Com o Supabase: Autentica usu√°rios (valida√ß√£o de JWT), realiza opera√ß√µes CRUD no banco de dados PostgreSQL, gerencia uploads/downloads de arquivos.
        
    - Com Google Gemini APIs: Envia prompts (potencialmente enriquecidos com contexto RAG) e recebe respostas geradas.
        
    - Com o Sistema RAG (em runtime): Acessa o √≠ndice vetorial (ou uma representa√ß√£o dele) para buscar chunks de texto relevantes para contextualizar prompts para os LLMs.
        
### 4.3. Supabase (BaaS)

- **Tecnologia:** Plataforma BaaS utilizando PostgreSQL.
    
- **Responsabilidades:**
    
    - **Autentica√ß√£o:** Gerenciamento de identidades de usu√°rios (cadastro, login, JWTs, RLS).
        
    - **Banco de Dados (PostgreSQL):** Persist√™ncia de todos os dados da aplica√ß√£o (dados de usu√°rios, vagas, curr√≠culos estruturados, hist√≥rico de intera√ß√µes, etc.).
        
    - **Storage:** Armazenamento seguro de arquivos enviados pelos usu√°rios (ex: PDFs de curr√≠culos originais).
        
    - **Realtime (Opcional, P√≥s-MVP):** Para funcionalidades que exigem atualiza√ß√µes em tempo real (ex: notifica√ß√µes no Kanban).
        
- **Intera√ß√µes Chave:**
    
    - Com a API Backend: Principal consumidor dos servi√ßos do Supabase.
        
    - Com o Frontend PWA (limitado): Pode interagir diretamente para autentica√ß√£o ou upload de arquivos, se a arquitetura permitir e for seguro.
        
### 4.4. Google Gemini LLMs (via OpenRouter)

- **Tecnologia:** Modelos Gemini Pro e Flash da Google.
    
- **Acesso:** Primariamente via OpenRouter para flexibilidade e gerenciamento.
    
- **Responsabilidades:**
    
    - Fornecer as capacidades de Processamento de Linguagem Natural (PLN) para:
        
        - Importa√ß√£o inteligente de vagas (extra√ß√£o de dados de URLs).
            
        - Categoriza√ß√£o sem√¢ntica de se√ß√µes de curr√≠culos.
            
        - An√°lise de adequa√ß√£o CV vs. Vaga (Score de Adequa√ß√£o).
            
        - Gera√ß√£o de sugest√µes de otimiza√ß√£o de CV.
            
        - Estimativa de range salarial.
            
        - Respostas e intera√ß√µes do Coach IA.
            
- **Intera√ß√µes Chave:**
    
    - Com a API Backend: Recebe prompts (enriquecidos com contexto RAG quando aplic√°vel) e retorna texto gerado ou an√°lises.
        
### 4.5. Sistema RAG Local (Infraestrutura em `rag_infra/`)

- **Tecnologias:** LangChain, FAISS-GPU, `BAAI/bge-m3` (via Sentence Transformers), Python, Conda.
    
- **Responsabilidades (Ambiente de Desenvolvimento/Manuten√ß√£o):**
    
    - Indexar a "Documenta√ß√£o Viva" (Markdown do Obsidian) e outros materiais de refer√™ncia (ex: artigos de PM, pesquisas salariais) da pasta `rag_infra/source_documents/`.
        
    - Processo: Carregar documentos, dividir em chunks, gerar embeddings vetoriais usando `BAAI/bge-m3`, e armazenar esses vetores em um √≠ndice FAISS-GPU (`rag_infra/data_index/faiss_index_bge_m3/`).
        
    - Fornecer uma maneira para os Agentes de IA (durante o desenvolvimento) e para o Backend API (em runtime, para certas funcionalidades) consultarem este √≠ndice para obter contexto relevante.
        
- **Intera√ß√µes Chave:**
    
    - Com a "Documenta√ß√£o Viva" (Obsidian): L√™ os documentos fonte.
        
    - Com os Agentes de IA (via Trae IDE/scripts): Permite que os agentes obtenham contexto espec√≠fico do projeto.
        
    - Com a API Backend (em runtime): A API Backend precisar√° de um mecanismo para consultar este √≠ndice (ou uma c√≥pia/servi√ßo derivado dele) para enriquecer prompts para os LLMs (ex: o Coach IA usando a base de conhecimento curada).
        
### 4.6. Agentes de IA (Trae IDE)

- **Tecnologia:** Configura√ß√µes e prompts customizados no Trae IDE, utilizando os LLMs Gemini.
    
- **Responsabilidades (Ambiente de Desenvolvimento e Metodologia):**
    
    - Auxiliar o Maestro em todas as fases do SDLC, conforme definido no [[docs/01_Guias_Centrais/GUIA_AVANCADO.md]].
        
    - Utilizar o Sistema RAG para obter contexto do projeto.
        
    - Gerar artefatos (c√≥digo, documenta√ß√£o, designs, HUs, casos de teste, etc.) sob a supervis√£o do Maestro (HITL).
        
- **Intera√ß√µes Chave:**
    
    - Com o Maestro (via Trae IDE): Recebe instru√ß√µes, fornece outputs.
        
    - Com o Sistema RAG Local: Obt√©m contexto.
        
    - Com os LLMs Gemini: Para suas capacidades de gera√ß√£o e racioc√≠nio.
        
### 4.7. Pipedream (Automa√ß√£o)

- **Tecnologia:** Plataforma de automa√ß√£o baseada em nuvem.
    
- **Responsabilidades:**
    
    - **CI/CD:** Automatizar os processos de build, teste e deploy do Frontend PWA (para Vercel) e da API Backend (para Render) a partir de gatilhos do reposit√≥rio Git.
        
    - **Automa√ß√£o de Tarefas:** Potencialmente, acionar a reindexa√ß√£o do RAG em commits na documenta√ß√£o, enviar notifica√ß√µes, etc.
        
- **Intera√ß√µes Chave:**
    
    - Com o Reposit√≥rio Git: Monitora pushes/merges.
        
    - Com Vercel/Render: Realiza deploys.
        
    - Com o Sistema RAG Local: Pode acionar scripts de reindexa√ß√£o.
        
### 4.8. Extens√£o de Navegador (Chrome - P√≥s-MVP)

- **Tecnologia:** JavaScript, HTML, CSS.
    
- **Responsabilidades:**
    
    - Permitir ao usu√°rio capturar facilmente informa√ß√µes de vagas de portais de emprego (inicialmente LinkedIn).
        
    - Comunicar-se com a API Backend para enviar os dados capturados.
        
- **Intera√ß√µes Chave:**
    
    - Com o Usu√°rio: Interface para captura e confirma√ß√£o.
        
    - Com Portais de Emprego: Extrai dados do DOM (requer cuidado com seletores e termos de uso).
        
    - Com a API Backend: Envia os dados da vaga capturada.
        
## 5. Fluxos de Dados Chave (Exemplos)

### 5.1. Fluxo de Autentica√ß√£o de Usu√°rio

1. Usu√°rio insere credenciais no Frontend PWA.
    
2. Frontend PWA envia credenciais para a API Backend.
    
3. API Backend encaminha para o servi√ßo de Autentica√ß√£o do Supabase.
    
4. Supabase valida, retorna JWT para a API Backend.
    
5. API Backend retorna JWT para o Frontend PWA.
    
6. Frontend PWA armazena JWT e o inclui em chamadas subsequentes.
    
### 5.2. Fluxo de Otimiza√ß√£o de CV

1. Usu√°rio seleciona uma vaga e um "Curr√≠culo Base Ativo" no Frontend PWA.
    
2. Frontend PWA envia ID da vaga e ID do curr√≠culo para a API Backend.
    
3. API Backend recupera a descri√ß√£o da vaga e o conte√∫do estruturado do curr√≠culo do Supabase.
    
4. API Backend envia a descri√ß√£o da vaga e o curr√≠culo para o LLM Gemini (via OpenRouter), possivelmente com contexto adicional do RAG (ex: melhores pr√°ticas de CV para aquela √°rea).
    
5. LLM Gemini analisa e retorna Score de Adequa√ß√£o, sugest√µes de otimiza√ß√£o e estimativa salarial.
    
6. API Backend processa a resposta do LLM e a envia para o Frontend PWA.
    
7. Frontend PWA exibe as informa√ß√µes ao usu√°rio.
    
### 5.3. Fluxo de Consulta ao RAG por um Agente de IA (Desenvolvimento)

1. Maestro interage com um Agente de IA no Trae IDE (ex: `@AgenteM_ArquitetoHLD` para discutir uma decis√£o de design).
    
2. O Trae IDE (ou a l√≥gica do `@AgenteOrquestrador`) formula uma consulta para o Sistema RAG Local com base na pergunta do Maestro.
    
3. O Sistema RAG Local (`rag_retriever.py`) busca no √≠ndice FAISS-GPU os chunks de texto mais relevantes da "Documenta√ß√£o Viva" (ex: ADRs existentes, HLD, ERS).
    
4. Os chunks recuperados s√£o injetados no prompt enviado ao LLM Gemini que motoriza o `@AgenteM_ArquitetoHLD`.
    
5. O `@AgenteM_ArquitetoHLD` utiliza esse contexto para gerar uma resposta mais informada e espec√≠fica para o projeto.
    
## 6. Considera√ß√µes Arquiteturais Chave

### 6.1. Escalabilidade

- **Frontend (Vercel) e Backend (Render):** Plataformas PaaS que oferecem escalabilidade autom√°tica ou gerenciada.
    
- **Supabase:** Projetado para escalar, com planos que suportam maior carga.
    
- **LLMs (OpenRouter):** Gerencia a escalabilidade das chamadas √†s APIs dos LLMs.
    
- **Sistema RAG Local:** Para o MVP, o RAG local com FAISS-GPU √© suficiente. Para escalar o RAG em produ√ß√£o para um grande n√∫mero de usu√°rios ou uma base de conhecimento muito din√¢mica, pode ser necess√°rio considerar solu√ß√µes de Vector DB gerenciadas na nuvem (ex: Supabase pgvector, Pinecone, Weaviate) e uma arquitetura de atualiza√ß√£o do √≠ndice mais robusta.
    
### 6.2. Seguran√ßa

- **Autentica√ß√£o e Autoriza√ß√£o:** Supabase Auth com JWTs e RLS no PostgreSQL.
    
- **Comunica√ß√£o:** HTTPS/TLS para todas as comunica√ß√µes entre componentes.
    
- **Valida√ß√£o de Dados:** Valida√ß√£o rigorosa de inputs no Frontend e, crucialmente, no Backend API (usando Pydantic).
    
- **Seguran√ßa de APIs LLM:** Gerenciamento seguro de chaves de API (ex: via vari√°veis de ambiente, `python-dotenv`).
    
- **OWASP Top 10 e OWASP LLM Top 10:** Considerar estas diretrizes no desenvolvimento.
    
- **LGPD:** Conformidade com a Lei Geral de Prote√ß√£o de Dados (ex: exclus√£o de dados do usu√°rio, consentimento).
    
### 6.3. Performance

- **Frontend:** Otimiza√ß√µes do Flutter Web, lazy loading, code splitting. Core Web Vitals como meta.
    
- **Backend:** FastAPI √© altamente perform√°tico. Otimiza√ß√£o de consultas ao banco de dados.
    
- **LLM:** Escolha entre Gemini Flash (mais r√°pido, menor custo) e Pro (mais capaz) conforme a necessidade da tarefa.
    
- **RAG:** FAISS-GPU para buscas vetoriais r√°pidas. Otimiza√ß√£o do tamanho dos chunks e da qualidade dos embeddings.
    
### 6.4. Manutenibilidade e Evolu√ß√£o

- **Modularidade:** Componentes bem definidos com responsabilidades claras.
    
- **"Documenta√ß√£o Viva":** Essencial para o entendimento e evolu√ß√£o do sistema.
    
- **Testes Automatizados:** Cobertura de testes unit√°rios e de integra√ß√£o.
    
- **CI/CD:** Automa√ß√£o de builds e deploys via Pipedream.
    
- **Stack Tecnol√≥gica Moderna:** Escolha de tecnologias com boas comunidades e perspectivas de futuro.
    
### 6.5. Custos

- Monitorar os custos de API dos LLMs, Supabase, Vercel, Render e Pipedream, especialmente para o modelo Freemium.
    
- Otimizar o uso de LLMs (ex: usar Gemini Flash sempre que poss√≠vel) e recursos de infraestrutura.
    
## 7. Implica√ß√µes para o LLD (Low-Level Design)

Este HLD estabelece a estrutura geral. Os LLDs para cada m√≥dulo principal (Autentica√ß√£o, Kanban, Otimiza√ß√£o de CV, Coach IA, etc.) precisar√£o detalhar:

- Modelos de dados espec√≠ficos (esquemas PostgreSQL).
    
- Estrutura detalhada dos endpoints da API Backend.
    
- Intera√ß√µes espec√≠ficas com os LLMs e o sistema RAG para cada funcionalidade de IA.
    
- Design de componentes de UI no Flutter.
    
- Algoritmos e l√≥gica de neg√≥cios complexa.
    
## 8. Riscos Arquiteturais e Estrat√©gias de Mitiga√ß√£o

- **Depend√™ncia de APIs Externas (LLMs, Supabase):**
    
    - _Mitiga√ß√£o:_ Design para resili√™ncia (circuit breakers, retries), monitoramento, ter planos de conting√™ncia ou abstra√ß√µes caso seja necess√°rio trocar de provedor (OpenRouter ajuda com LLMs).
        
- **Complexidade da Integra√ß√£o RAG em Runtime:**
    
    - _Mitiga√ß√£o:_ Come√ßar com um escopo limitado para o RAG em runtime (ex: apenas para o Coach IA), prototipar e testar exaustivamente.
        
- **Performance do Parsing de PDF e An√°lise de CV:**
    
    - _Mitiga√ß√£o:_ Otimizar o pipeline de parsing, usar LLMs eficientes (Gemini Flash), fornecer feedback ao usu√°rio durante processos longos.
        
- **Gerenciamento de Custos de IA:**
    
    - _Mitiga√ß√£o:_ Implementar limites de uso (tiers), otimizar prompts, usar modelos mais baratos quando apropriado, monitorar custos de perto.
        

--- FIM DO DOCUMENTO HLD_Recoloca.ai (v1.0) ---